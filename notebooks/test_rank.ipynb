{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Union, Dict\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import Column\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/21 09:58:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# master configuration to use only 4 CPU cores\n",
    "spark = SparkSession.builder.master(\"local[4]\").getOrCreate()\n",
    "\n",
    "# basic configuration to use only a reasonable number of partitions\n",
    "spark.conf.set(\"spark.sql.shuffle.partition\", 4)\n",
    "\n",
    "# configuration to work in UTC\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate(df: DataFrame, config: dict) -> DataFrame:\n",
    "        order_by_dict = config[\"order_by\"]\n",
    "        partition_by = config[\"key_columns\"]\n",
    "        dedup_type = config.get(\"type\", \"row_number\")\n",
    "\n",
    "        window_func = Window.partitionBy(partition_by).orderBy(\n",
    "            *[\n",
    "                F.col(col).desc() if order == \"desc\" else F.col(col).asc()\n",
    "                for col, order in order_by_dict.items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if dedup_type == \"row_number\":\n",
    "            df = df.withColumn(\"wf_col\", F.row_number().over(window_func))\n",
    "        elif dedup_type == \"rank\":\n",
    "            df = df.withColumn(\"wf_col\", F.rank().over(window_func))\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"\"\"Deduplication type should be either row_number,\n",
    "                empty (row_number as default) or rank. Not {dedup_type}\"\"\"\n",
    "            )\n",
    "        return df.filter(F.col(\"wf_col\") == 1).drop(\"wf_col\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyConfig:\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.config[key]\n",
    "\n",
    "    def get(self, key, default=None):\n",
    "        return self.config.get(key, default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_path = \"/Users/emilianofrigo/repositories/pipelines-tooling/tests/unit/spark_operations/deduplicate/resources/input_rank.json\"\n",
    "\n",
    "input_df = spark.read.json(input_path, multiLine=True)\n",
    "\n",
    "\n",
    "config = DummyConfig(\n",
    "    {\n",
    "        \"key_columns\": [\"Subject\"],\n",
    "        \"order_by\": {\"Score\": \"desc\"},\n",
    "        \"type\": \"rank\",\n",
    "    }\n",
    ")\n",
    "\n",
    "actual_df = deduplicate(input_df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|Score|Student|Subject|\n",
      "+-----+-------+-------+\n",
      "|   95|Charlie|   Math|\n",
      "|   95|    Eva|Science|\n",
      "|   95|    Eva|Science|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
