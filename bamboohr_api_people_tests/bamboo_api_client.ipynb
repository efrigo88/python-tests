{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql.types import StringType\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import DataFrame, SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BambooHR API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used https://jsonplaceholder.typicode.com/ as a sample API to build the logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BambooHRClient:\n",
    "    \"\"\"A client for the BambooHR API.\n",
    "    \n",
    "    This client handles authentication, session management, and API requests\n",
    "    to the BambooHR API or a placeholder API for demonstration purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    # BASE_URL = \"https://api.bamboohr.com/api/gateway.php/{company_domain}/v1\"\n",
    "    BASE_URL = \"https://jsonplaceholder.{company_domain}.com\"\n",
    "    ENDPOINTS = {\n",
    "        \"posts\": \"/posts\",\n",
    "        \"albums\": \"/albums\",\n",
    "        \"users\": \"/users\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, api_key, company_domain):\n",
    "        \"\"\"\n",
    "        Initialize the BambooHRClient with an API key and company domain.\n",
    "\n",
    "        Args:\n",
    "            api_key (str): The API key for authenticating requests.\n",
    "            company_domain (str): The domain of the company for API requests.\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.company_domain = company_domain\n",
    "        self.base_url = self.BASE_URL.format(company_domain=company_domain)\n",
    "        self.session = self._create_session()\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Basic {self.api_key}\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        }\n",
    "    \n",
    "    def _create_session(self) -> requests.Session:\n",
    "        \"\"\"Create a session with a retry strategy for handling transient errors.\"\"\"\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=2,\n",
    "            status_forcelist=[429, 503],\n",
    "            allowed_methods=[\"GET\"],\n",
    "        )\n",
    "\n",
    "        # Create an adapter with the retry strategy\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "        # Create a session and mount the adapter\n",
    "        session = requests.Session()\n",
    "        session.mount(\"https://\", adapter)\n",
    "\n",
    "        return session\n",
    "\n",
    "    def get(self, endpoint_key: str, params: dict = None) -> dict:\n",
    "        \"\"\"\n",
    "        Fetch data from a specified endpoint using the endpoint key.\n",
    "\n",
    "        Args:\n",
    "            endpoint_key (str): The key for the desired endpoint (e.g., \"posts\").\n",
    "            params (dict, optional): Query parameters to include in the request.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an invalid endpoint key is provided.\n",
    "            requests.exceptions.RequestException: If the request fails.\n",
    "\n",
    "        Example:\n",
    "            >>> client = BambooHRClient(api_key=\"my_api_key\", company_domain=\"typicode\")\n",
    "            >>> posts = client.get(\"posts\")\n",
    "            >>> print(posts)\n",
    "        \"\"\"\n",
    "        endpoint = self.ENDPOINTS.get(endpoint_key)\n",
    "        if not endpoint:\n",
    "            raise ValueError(f\"Invalid endpoint key: {endpoint_key}\")\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        response = self.session.get(url, headers=self.headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}]\n",
      "[{'userId': 1, 'id': 1, 'title': 'quidem molestiae enim'}]\n",
      "[{'id': 1, 'name': 'Leanne Graham', 'username': 'Bret', 'email': 'Sincere@april.biz', 'address': {'street': 'Kulas Light', 'suite': 'Apt. 556', 'city': 'Gwenborough', 'zipcode': '92998-3874', 'geo': {'lat': '-37.3159', 'lng': '81.1496'}}, 'phone': '1-770-736-8031 x56442', 'website': 'hildegard.org', 'company': {'name': 'Romaguera-Crona', 'catchPhrase': 'Multi-layered client-server neural-net', 'bs': 'harness real-time e-markets'}}]\n"
     ]
    }
   ],
   "source": [
    "API_KEY = \"<your_api_key>\"\n",
    "COMPANY_DOMAIN = \"typicode\"\n",
    "\n",
    "# Initialize the client\n",
    "client = BambooHRClient(\n",
    "    api_key=API_KEY, \n",
    "    company_domain=COMPANY_DOMAIN\n",
    ")\n",
    "\n",
    "posts = client.get(\"posts\")\n",
    "albums = client.get(\"albums\")\n",
    "users = client.get(\"users\")\n",
    "\n",
    "print(posts[:1])\n",
    "print(albums[:1])\n",
    "print(users[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data directory and save the json outputs to check responses.\n",
    "\n",
    "# os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# def save_json_data(data: dict, filename: str) -> None:\n",
    "#     with open(f\"data/{filename}\", \"w\") as f:\n",
    "#         json.dump(data, f, indent=4)\n",
    "#     print(f\"{filename} file saved successfully\")\n",
    "\n",
    "# for data, data_name in zip([posts, albums, users], [\"posts\", \"albums\", \"users\"]):\n",
    "#     save_json_data(data, f\"{data_name}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and Save data in delta format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaFileManager:\n",
    "    \"\"\"Handles the creation, transformation, and storage of data in Delta format.\"\"\"\n",
    "\n",
    "    def __init__(self, app_name: str = \"MyApp\"):\n",
    "        \"\"\"Initializes the Spark session with Delta Lake configurations.\"\"\"\n",
    "        builder = (\n",
    "            SparkSession.builder.appName(app_name)\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "            .config(\n",
    "                \"spark.sql.catalog.spark_catalog\",\n",
    "                \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "            )\n",
    "        )\n",
    "        self.spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "    def convert_to_json_string(self, data: List[dict]) -> list:\n",
    "        \"\"\"\n",
    "        Converts a list of dictionaries into a list of JSON strings.\n",
    "\n",
    "        This method serializes each dictionary in the input list into a JSON-formatted\n",
    "        string. The `default=str` parameter ensures that non-serializable types\n",
    "        (e.g., datetime objects) are converted to strings during serialization.\n",
    "        \"\"\"\n",
    "        return [json.dumps(record, default=str) for record in data]\n",
    "\n",
    "    def create_schemaless_df(self, json_strings: list) -> DataFrame:\n",
    "        \"\"\"Converts a list of JSON strings into a schemaless DataFrame.\"\"\"\n",
    "        return self.spark.createDataFrame(json_strings, StringType())\n",
    "\n",
    "    def add_timestamp_column(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"Adds a processed timestamp column to a DataFrame.\"\"\"\n",
    "        return df.withColumn(\"processed_at\", F.current_timestamp())\n",
    "\n",
    "    def save_to_delta(\n",
    "        self, df: DataFrame, path: str, repartition: int = 1, mode: str = \"append\"\n",
    "    ):\n",
    "        \"\"\"Saves a DataFrame to a Delta table.\"\"\"\n",
    "        df.repartition(repartition).write.format(\"delta\").mode(mode).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Initialize the manager\n",
    "manager = DeltaFileManager()\n",
    "\n",
    "# Prepare input files into json_strings\n",
    "posts_string = manager.convert_to_json_string(posts)\n",
    "albums_string = manager.convert_to_json_string(albums)\n",
    "users_string = manager.convert_to_json_string(users)\n",
    "\n",
    "# Create schemaless DataFrames\n",
    "posts_df = manager.create_schemaless_df(posts_string)\n",
    "albums_df = manager.create_schemaless_df(albums_string)\n",
    "users_df = manager.create_schemaless_df(users_string)\n",
    "\n",
    "# Add a timestamp column\n",
    "posts_df = manager.add_timestamp_column(posts_df)\n",
    "albums_df = manager.add_timestamp_column(albums_df)\n",
    "users_df = manager.add_timestamp_column(users_df)\n",
    "\n",
    "# Save to Delta tables\n",
    "manager.save_to_delta(posts_df, \"data/delta_tables/posts\", mode=\"overwrite\")\n",
    "manager.save_to_delta(albums_df, \"data/delta_tables/albums\", mode=\"overwrite\")\n",
    "manager.save_to_delta(users_df, \"data/delta_tables/users\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- processed_at: timestamp (nullable = false)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- processed_at: timestamp (nullable = false)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- processed_at: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schemas\n",
    "posts_df.printSchema()\n",
    "albums_df.printSchema()\n",
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|value                                                                                                                                                                                                                                                                                     |processed_at           |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|{\"userId\": 1, \"id\": 1, \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\", \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"}|2025-01-10 20:30:40.838|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------------------------------------------+-----------------------+\n",
      "|value                                                   |processed_at           |\n",
      "+--------------------------------------------------------+-----------------------+\n",
      "|{\"userId\": 1, \"id\": 1, \"title\": \"quidem molestiae enim\"}|2025-01-10 20:30:40.943|\n",
      "+--------------------------------------------------------+-----------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|value                                                                                                                                                                                                                                                                                                                                                                                                                                            |processed_at           |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|{\"id\": 1, \"name\": \"Leanne Graham\", \"username\": \"Bret\", \"email\": \"Sincere@april.biz\", \"address\": {\"street\": \"Kulas Light\", \"suite\": \"Apt. 556\", \"city\": \"Gwenborough\", \"zipcode\": \"92998-3874\", \"geo\": {\"lat\": \"-37.3159\", \"lng\": \"81.1496\"}}, \"phone\": \"1-770-736-8031 x56442\", \"website\": \"hildegard.org\", \"company\": {\"name\": \"Romaguera-Crona\", \"catchPhrase\": \"Multi-layered client-server neural-net\", \"bs\": \"harness real-time e-markets\"}}|2025-01-10 20:30:41.021|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "posts_df.show(1, truncate=False)\n",
    "albums_df.show(1, truncate=False)\n",
    "users_df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload JSONs outputs to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3Helper:\n",
    "    \"\"\"Utility class for handling S3 operations.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            aws_access_key_id: str, \n",
    "            aws_secret_access_key: str, \n",
    "            region_name: str = \"eu-east-1\"\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initializes the S3Helper with AWS credentials and region.\n",
    "\n",
    "        Args:\n",
    "            aws_access_key_id (str): Your AWS access key ID.\n",
    "            aws_secret_access_key (str): Your AWS secret access key.\n",
    "            region_name (str): The AWS region to connect to (default: \"us-east-1\").\n",
    "        \"\"\"\n",
    "        self.s3_client = boto3.client(\n",
    "            \"s3\",\n",
    "            aws_access_key_id=aws_access_key_id,\n",
    "            aws_secret_access_key=aws_secret_access_key,\n",
    "            region_name=region_name,\n",
    "        )\n",
    "\n",
    "    def upload_json(self, data: List[dict], s3_path: str, bucket: str):\n",
    "        \"\"\"\n",
    "        Upload JSON data to an S3 bucket.\n",
    "\n",
    "        Args:\n",
    "            data (List[dict]): The data to upload.\n",
    "            s3_path (str): The S3 key/path where the file will be saved.\n",
    "            bucket (str): The S3 bucket name.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            json_data = json.dumps(data)\n",
    "            self.s3_client.put_object(Bucket=bucket, Key=s3_path, Body=json_data)\n",
    "            print(f\"Successfully uploaded data to s3://{bucket}/{s3_path}\")\n",
    "        except (BotoCoreError, ClientError) as e:\n",
    "            print(\"Failed to upload data to S3.\", e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data to s3://landing-bucket-1cc1ed4e8908/posts/2025-01-14.json\n",
      "Successfully uploaded data to s3://landing-bucket-1cc1ed4e8908/albums/2025-01-14.json\n",
      "Successfully uploaded data to s3://landing-bucket-1cc1ed4e8908/users/2025-01-14.json\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch credentials\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "aws_region = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "# Initialize the helper\n",
    "s3_helper = S3Helper(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=aws_region,\n",
    ")\n",
    "\n",
    "_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Upload files\n",
    "s3_helper.upload_json(\n",
    "    posts, \n",
    "    bucket=\"landing-bucket-1cc1ed4e8908\",\n",
    "    s3_path=f\"posts/{_date}.json\"\n",
    ")\n",
    "s3_helper.upload_json(\n",
    "    albums, \n",
    "    bucket=\"landing-bucket-1cc1ed4e8908\",\n",
    "    s3_path=f\"albums/{_date}.json\"\n",
    ")\n",
    "s3_helper.upload_json(\n",
    "    users, \n",
    "    bucket=\"landing-bucket-1cc1ed4e8908\",\n",
    "    s3_path=f\"users/{_date}.json\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
