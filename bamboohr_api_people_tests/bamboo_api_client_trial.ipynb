{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "from typing import List, Union\n",
    "from dotenv import load_dotenv\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import DataFrame, SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "domain = os.getenv(\"COMPANY_DOMAIN\")\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "encryption_key = os.getenv(\"ENCRYPTION_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BambooHR API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPLOYEES_REPORT_PAYLOAD = {\n",
    "    \"title\": \"custom-employees\",\n",
    "    \"fields\": [\n",
    "        \"displayName\",\n",
    "        \"firstName\",\n",
    "        \"lastName\",\n",
    "        \"preferredName\",\n",
    "        \"dateOfBirth\",\n",
    "        \"maritalStatus\",\n",
    "        \"ssn\",\n",
    "        \"gender\",\n",
    "        \"pronouns\",\n",
    "        \"country\",\n",
    "        \"city\",\n",
    "        \"zipcode\",\n",
    "        \"address1\",\n",
    "        \"address2\",\n",
    "        \"employee_access\",\n",
    "        \"customShirtsize\",\n",
    "        \"customHobbies\",\n",
    "        \"allergies\",\n",
    "        \"dietaryRestrictions\",\n",
    "        \"jobTitle\",\n",
    "        \"hireDate\",\n",
    "        \"originalHireDate\",\n",
    "        \"employeeStatusDate\",\n",
    "        \"employmentStatus\",\n",
    "        \"employmentHistoryStatus\",  # FTE\n",
    "        \"terminationDate\",\n",
    "        \"location\",\n",
    "        \"workPhone\",\n",
    "        \"mobilePhone\",\n",
    "        \"workEmail\",\n",
    "        \"department\",\n",
    "        \"division\",\n",
    "        \"workPhoneExtension\",\n",
    "        \"supervisor\",\n",
    "        \"supervisorEid\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BambooHRClient:\n",
    "    \"\"\"A client for the BambooHR API.\"\"\"\n",
    "\n",
    "    ENDPOINTS = {\n",
    "        \"company_information\": \"/company_information\",\n",
    "        # Headcount\n",
    "        \"employees\": \"/reports/custom\",\n",
    "        \"employees_changed\": \"/employees/changed\",\n",
    "        \"account_info_fields\": \"/meta/fields\",\n",
    "        \"account_info_tab_fields\": \"/meta/tables\",\n",
    "        \"account_list_fields\": \"/meta/lists\",\n",
    "        \"account_list_users\": \"/meta/users\",\n",
    "        # Time Off\n",
    "        \"time_off_types\": \"/meta/time_off/types\",\n",
    "        \"time_off_policies\": \"/meta/time_off/policies\",\n",
    "        \"time_off_requests\": \"/time_off/requests\",\n",
    "        \"time_off_whos_out\": \"/time_off/whos_out\",\n",
    "        # Hiring\n",
    "        \"applicant_tracking_jobs\": \"/applicant_tracking/jobs\",\n",
    "        \"applicant_tracking_applications\": \"/applicant_tracking/applications\",\n",
    "        \"applicant_application_details\": \"/applicant_tracking/applications/{appId}\",\n",
    "        ##\n",
    "        \"custom_report_test\": \"/reports/101\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, api_key: str, days_offset: int = 1):\n",
    "        \"\"\"Initialize the BambooHRClient with an API key and a dynamically set domain.\"\"\"\n",
    "        self.domain = domain\n",
    "        self.base_url = f\"https://api.bamboohr.com/api/gateway.php/{self.domain}/v1\"\n",
    "        self.api_key = api_key\n",
    "        self.days_offset = days_offset\n",
    "        self.session = self._create_session()\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": self._encode_auth_header(api_key),\n",
    "        }\n",
    "\n",
    "    def _encode_auth_header(self, api_key: str) -> str:\n",
    "        \"\"\"Encode the API key in Base64 for the Authorization header.\"\"\"\n",
    "        auth_string = f\"{api_key}:x\"\n",
    "        encoded_bytes = base64.b64encode(auth_string.encode(\"utf-8\"))\n",
    "        return f\"Basic {encoded_bytes.decode('utf-8')}\"\n",
    "\n",
    "    def _build_query_string(self, params: dict) -> str:\n",
    "        \"\"\"Helper method to construct a query string from a dictionary.\"\"\"\n",
    "        return \"&\".join(f\"{k}={v}\" for k, v in params.items())\n",
    "\n",
    "    def _create_session(self) -> requests.Session:\n",
    "        \"\"\"Create a session with a retry strategy for handling transient errors.\"\"\"\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=2,\n",
    "            status_forcelist=[429, 503],\n",
    "            allowed_methods=[\"GET\", \"POST\"],\n",
    "        )\n",
    "\n",
    "        # Create an adapter with the retry strategy\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "        # Create a session and mount the adapter\n",
    "        session = requests.Session()\n",
    "        session.mount(\"https://\", adapter)\n",
    "\n",
    "        return session\n",
    "\n",
    "    def get(\n",
    "        self, endpoint_key: str = None, endpoint_path: str = None, params: dict = None\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Fetch data from a specified endpoint using the endpoint key or a direct endpoint path.\n",
    "\n",
    "        Args:\n",
    "            endpoint_key (str, optional): The key for the desired endpoint (e.g., \"posts\"). Defaults to None.\n",
    "            endpoint_path (str, optional): The direct path for the endpoint (e.g., \"/employees/123\"). Defaults to None.\n",
    "            params (dict, optional): Query parameters to include in the request.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If neither `endpoint_key` nor `endpoint_path` is provided.\n",
    "            requests.exceptions.RequestException: If the request fails.\n",
    "        \"\"\"\n",
    "        if endpoint_key:\n",
    "            endpoint = self.ENDPOINTS.get(endpoint_key)\n",
    "            if not endpoint:\n",
    "                raise ValueError(f\"Invalid endpoint key: {endpoint_key}\")\n",
    "        elif endpoint_path:\n",
    "            endpoint = endpoint_path\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"You must provide either an endpoint_key or an endpoint_path.\"\n",
    "            )\n",
    "\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        response = self.session.get(url, headers=self.headers, params=params)\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed with status {response.status_code}: {e}\")\n",
    "            raise\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "    def get_employees_changed(self, change_type: str = None) -> dict:\n",
    "        \"\"\"\n",
    "        Fetch the list of employees changed since a given number of days ago.\n",
    "\n",
    "        Args:\n",
    "            change_type (str, optional): Type of change to filter for (\"inserted\", \"updated\", \"deleted\").\n",
    "                If not provided, all change types will be included.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API, containing the list of employees\n",
    "                who have changed since the specified timestamp.\n",
    "        \"\"\"\n",
    "        since = datetime.now(timezone.utc) - timedelta(days=self.days_offset)\n",
    "        since = since.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        params = {\"since\": since}\n",
    "        if change_type:\n",
    "            params[\"type\"] = change_type\n",
    "\n",
    "        return self.get(\"employees_changed\", params=params)\n",
    "\n",
    "    def get_time_off_request(self) -> dict:\n",
    "        \"\"\"\n",
    "        Fetch time-off requests within a specified date range.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API, containing the list of time-off\n",
    "                requests within the specified date range.\n",
    "        \"\"\"\n",
    "        start_dt = datetime.now(timezone.utc) - timedelta(days=self.days_offset)\n",
    "        end_dt = datetime.now(timezone.utc)\n",
    "        start_dt = start_dt.strftime(\"%Y-%m-%d\")\n",
    "        end_dt = end_dt.strftime(\"%Y-%m-%d\")\n",
    "        params = {\n",
    "            \"start\": start_dt,\n",
    "            \"end\": end_dt,\n",
    "        }\n",
    "\n",
    "        return self.get(\"time_off_requests\", params=params)\n",
    "\n",
    "    def get_appl_trk_apps(self) -> dict:\n",
    "        \"\"\"\n",
    "        Fetches applicant tracking applications updated since a specified number of days ago.\n",
    "\n",
    "        This method generates the `newSince` query parameter using the current UTC time\n",
    "        minus the specified number of days. It then sends a GET request to the\n",
    "        `applicant_tracking_applications` endpoint with the constructed parameter.\n",
    "\n",
    "        Returns:\n",
    "            dict: The API response containing applicant tracking applications.\n",
    "        \"\"\"\n",
    "        new_since = datetime.now(timezone.utc) - timedelta(days=self.days_offset)\n",
    "        new_since = new_since.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        params = {\"newSince\": new_since}\n",
    "\n",
    "        return self.get(\"applicant_tracking_applications\", params=params)\n",
    "\n",
    "    def get_application_details(self) -> list:\n",
    "        \"\"\"\n",
    "        Fetches detailed information for each application in the applicant tracking system.\n",
    "\n",
    "        This method first retrieves a list of applications using the `get_appl_trk_apps` method,\n",
    "        extracts their IDs, and then fetches detailed information for each application by calling\n",
    "        the BambooHR API endpoint `/applicant_tracking/applications/{applicationId}`.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries, where each dictionary contains detailed data for a single application.\n",
    "\n",
    "        Notes:\n",
    "            - The method uses the `get_appl_trk_apps` method to fetch the initial list of applications.\n",
    "            - The `get` method is used with `endpoint_path` to fetch details for each `applicationId`.\n",
    "\n",
    "        Error Handling:\n",
    "            - If an exception occurs during the detailed fetch for a specific application,\n",
    "            the method logs the error and continues processing the remaining application IDs.\n",
    "        \"\"\"\n",
    "        # Fetch the initial applications report and get the application IDs\n",
    "        applications_report = self.get_appl_trk_apps()\n",
    "        application_ids = [\n",
    "            app[\"id\"] for app in applications_report.get(\"applications\", [])\n",
    "        ]\n",
    "        # Fetch detailed data for each application\n",
    "        detailed_applications = []\n",
    "        for app_id in application_ids:\n",
    "            try:\n",
    "                details = self.get(\n",
    "                    endpoint_path=f\"/applicant_tracking/applications/{app_id}\"\n",
    "                )\n",
    "                detailed_applications.append(details)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to fetch details for application ID {app_id}: {e}\")\n",
    "\n",
    "        return detailed_applications\n",
    "\n",
    "    def post(\n",
    "        self, endpoint_key: str, data: dict = None, query_params: dict = None\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Send data to a specified endpoint using the POST method.\n",
    "\n",
    "        Args:\n",
    "            endpoint_key (str): The key for the desired endpoint.\n",
    "            data (dict, optional): The JSON payload to send in the POST request.\n",
    "            query_params (dict, optional): Query parameters to include in the URL.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an invalid endpoint key is provided.\n",
    "            requests.exceptions.RequestException: If the request fails.\n",
    "        \"\"\"\n",
    "        endpoint = self.ENDPOINTS.get(endpoint_key)\n",
    "        if not endpoint:\n",
    "            raise ValueError(f\"Invalid endpoint key: {endpoint_key}\")\n",
    "\n",
    "        if query_params:\n",
    "            query_string = self._build_query_string(query_params)\n",
    "            url = f\"{self.base_url}{endpoint}?{query_string}\"\n",
    "        else:\n",
    "            url = f\"{self.base_url}{endpoint}\"\n",
    "\n",
    "        response = self.session.post(url, headers=self.headers, json=data)\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed with status {response.status_code}: {e}\")\n",
    "            raise\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "    def create_employees_report(self) -> dict:\n",
    "        \"\"\"\n",
    "        Generate a custom report of employees and all their relevant data.\n",
    "\n",
    "        Returns:\n",
    "            dict: The formatted report with each employee's data as a separate row.\n",
    "        \"\"\"\n",
    "        payload = EMPLOYEES_REPORT_PAYLOAD\n",
    "        q_params = {\"format\": \"json\", \"onlyCurrent\": \"true\"}\n",
    "\n",
    "        # Get the response from the API\n",
    "        response = self.post(\"employees\", data=payload, query_params=q_params)\n",
    "\n",
    "        # Extract and format the employees data\n",
    "        employees = response.get(\"employees\", [])\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        # Create formatted employee rows with consistent fields\n",
    "        # Use OrderedDict to preserve key order for each employee\n",
    "        formatted_employees = [OrderedDict((key, employee.get(key)) for key in employee) for employee in employees]\n",
    "\n",
    "        return formatted_employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = BambooHRClient(api_key=api_key, days_offset=30)\n",
    "\n",
    "# Create a data directory to store the JSON outputs\n",
    "os.makedirs(\"data/api_response\", exist_ok=True)\n",
    "\n",
    "\n",
    "def save_json_data(data: dict, filename: str) -> None:\n",
    "    \"\"\"Save JSON data to a file.\"\"\"\n",
    "    with open(f\"data/api_response/{filename}\", \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"{filename} file saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employees.json file saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Map report methods or endpoint keys to filenames\n",
    "report_mappings = {\n",
    "    \"company_information\": \"company_information.json\",\n",
    "    \"employees\": lambda: client.create_employees_report(),\n",
    "    \"employees_changed\": lambda: client.get_employees_changed(),\n",
    "    \"account_info_fields\": \"account_info_fields.json\",\n",
    "    \"account_info_tab_fields\": \"account_info_tab_fields.json\",\n",
    "    \"account_list_fields\": \"account_list_fields.json\",\n",
    "    \"account_list_users\": \"account_list_users.json\",\n",
    "    \"time_off_types\": \"time_off_types.json\",\n",
    "    \"time_off_policies\": \"time_off_policies.json\",\n",
    "    \"time_off_requests\": lambda: client.get_time_off_request(),\n",
    "    \"time_off_whos_out\": \"time_off_whos_out.json\",\n",
    "    \"applicant_tracking_jobs\": \"applicant_tracking_jobs.json\",\n",
    "    \"applicant_tracking_applications\": lambda: client.get_appl_trk_apps(),\n",
    "    \"applicant_application_details\": lambda: client.get_application_details(),\n",
    "    # \"custom_report_test\": \"custom_report_test.json\",\n",
    "}\n",
    "\n",
    "# Fetch and save reports dynamically\n",
    "for report_key, filename_or_callable in report_mappings.items():\n",
    "    if callable(filename_or_callable):\n",
    "        data = filename_or_callable()\n",
    "        filename = f\"{report_key}.json\"\n",
    "    else:\n",
    "        data = client.get(endpoint_key=report_key)\n",
    "        filename = filename_or_callable\n",
    "    save_json_data(data, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and Save data in delta format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaFileManager:\n",
    "    \"\"\"Handles the creation, transformation, and storage of data in Delta format.\"\"\"\n",
    "\n",
    "    def __init__(self, app_name: str = \"MyApp\", encryption_key: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the Spark session with Delta Lake configurations and optionally sets the encryption key.\n",
    "\n",
    "        Args:\n",
    "            app_name (str): Name of the Spark application.\n",
    "            encryption_key (str): Encryption key for AES encryption (default: None).\n",
    "        \"\"\"\n",
    "        self.spark = (\n",
    "            SparkSession.builder\n",
    "            .appName(app_name)\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "            .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\")\n",
    "            .getOrCreate()\n",
    "        )\n",
    "        self.encryption_key = encryption_key\n",
    "\n",
    "    def convert_to_json_string(self, data: Union[List[dict], dict]) -> list:\n",
    "        \"\"\"\n",
    "        Converts a dictionary or a list of dictionaries into a list of JSON strings.\n",
    "\n",
    "        Args:\n",
    "            data (Union[List[dict], dict]): The input data, either a list of dictionaries\n",
    "                or a single dictionary.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of JSON strings.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input data is neither a list of dictionaries nor a dictionary.\n",
    "        \"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            # Convert a single dictionary to a JSON string\n",
    "            return [json.dumps(data, default=str)]\n",
    "        elif isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
    "            # Convert each dictionary in the list to a JSON string\n",
    "            return [json.dumps(record, default=str) for record in data]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Input data must be a dictionary or a list of dictionaries.\"\n",
    "            )\n",
    "\n",
    "    def create_schemaless_df(self, json_strings: list) -> DataFrame:\n",
    "        \"\"\"Converts a list of JSON strings into a schemaless DataFrame.\"\"\"\n",
    "        return self.spark.createDataFrame(json_strings, StringType())\n",
    "\n",
    "    def add_processed_dt(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"Adds a processed timestamp column to a DataFrame.\"\"\"\n",
    "        return df.withColumn(\"processed_at\", F.current_timestamp())\n",
    "\n",
    "    def encrypt_columns(\n",
    "        self,\n",
    "        df: DataFrame,\n",
    "        columns: list,\n",
    "        encryption_mode: str = \"ECB\",\n",
    "    ) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Encrypts the specified columns in the DataFrame using AES encryption and Base64 encoding.\n",
    "\n",
    "        Args:\n",
    "            df (DataFrame): The input DataFrame.\n",
    "            columns (list): List of column names to encrypt.\n",
    "            encryption_mode (str): The encryption mode for AES (default: \"ECB\").\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with encrypted columns.\n",
    "        \"\"\"\n",
    "        if not self.encryption_key:\n",
    "            raise ValueError(\n",
    "                \"Encryption key is not set. Please provide an encryption key.\"\n",
    "            )\n",
    "\n",
    "        for col_name in columns:\n",
    "            encrypted_col = F.expr(\n",
    "                f\"aes_encrypt({col_name}, '{self.encryption_key}', '{encryption_mode}')\"\n",
    "            )\n",
    "            base64_encoded_col = F.base64(encrypted_col)\n",
    "            df = df.withColumn(col_name, base64_encoded_col)\n",
    "        return df\n",
    "\n",
    "    def save_to_delta(\n",
    "        self, df: DataFrame, path: str, repartition: int = 1, mode: str = \"append\"\n",
    "    ):\n",
    "        \"\"\"Saves a DataFrame to a Delta table.\"\"\"\n",
    "        df.repartition(repartition).write.format(\"delta\").mode(mode).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: time_off_types\n",
      "Processed and saved: applicant_tracking_applications\n",
      "Processed and saved: time_off_requests\n",
      "Processed and saved: account_list_fields\n",
      "Processed and saved: applicant_tracking_jobs\n",
      "Processed and saved: applicant_application_details\n",
      "Processed and saved: account_info_tab_fields\n",
      "Processed and saved: employees_changed\n",
      "Processed and saved: time_off_whos_out\n",
      "Processed and saved: time_off_policies\n",
      "Processed and saved: account_info_fields\n",
      "Processed and saved: employees\n",
      "Processed and saved: company_information\n",
      "Processed and saved: account_list_users\n"
     ]
    }
   ],
   "source": [
    "# Initialize the manager\n",
    "manager = DeltaFileManager(encryption_key=encryption_key)\n",
    "\n",
    "# Directory containing JSON files\n",
    "data_folder = \"data/api_response/\"\n",
    "\n",
    "# Iterate over all JSON files in the folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        # Read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        # Convert the JSON data to JSON strings\n",
    "        json_strings = manager.convert_to_json_string(data)\n",
    "        # Create schemaless DataFrame\n",
    "        df = manager.create_schemaless_df(json_strings)\n",
    "        # Add a processed timestamp column\n",
    "        df = manager.add_processed_dt(df)\n",
    "        # Encrypt data (if required)\n",
    "        df = manager.encrypt_columns(df, columns=[\"value\"])\n",
    "        # Generate a Delta table path based on the filename\n",
    "        table_name = filename.replace(\".json\", \"\")\n",
    "        delta_table_path = f\"data/delta_tables/{table_name}\"\n",
    "        # Save the DataFrame to Delta table\n",
    "        manager.save_to_delta(df, delta_table_path, mode=\"overwrite\")\n",
    "\n",
    "        print(f\"Processed and saved: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypt value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_columns(\n",
    "    df: DataFrame,\n",
    "    columns: list,\n",
    "    encryption_key: str = encryption_key,\n",
    "    encryption_mode: str = \"ECB\",\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Decrypts the specified columns in the DataFrame using AES decryption and Base64 decoding.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        columns (list): List of column names to decrypt.\n",
    "        encryption_key (str): The decryption key for AES decryption.\n",
    "        encryption_mode (str): The decryption mode for AES (default: \"ECB\").\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with decrypted columns.\n",
    "    \"\"\"\n",
    "    for col_name in columns:\n",
    "        decrypted_col = F.expr(\n",
    "            f\"aes_decrypt(unbase64({col_name}), '{encryption_key}', '{encryption_mode}')\"\n",
    "        ).cast(\"string\")\n",
    "        df = df.withColumn(col_name, decrypted_col)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |processed_at           |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "|{\"id\": \"4\", \"displayName\": \"Charlotte Abbott\", \"firstName\": \"Charlotte\", \"lastName\": \"Abbott\", \"preferredName\": null, \"dateOfBirth\": \"1997-04-07\", \"maritalStatus\": null, \"ssn\": \"555-64-8712\", \"gender\": \"Female\", \"pronouns\": null, \"country\": \"United States\", \"city\": \"Lindon\", \"zipcode\": \"84042\", \"address1\": \"335 S 560 W\", \"address2\": null, \"customShirtsize\": \"2. Medium\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Peanut allergy\", \"jobTitle\": \"Sr. HR Administrator\", \"hireDate\": \"2023-12-28\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2021-12-27\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Lindon, Utah\", \"workPhone\": \"801-724-6600\", \"mobilePhone\": \"801-724-6600\", \"workEmail\": \"cabbott@efficientoffice.com\", \"department\": \"Human Resources\", \"division\": \"North America\", \"workPhoneExtension\": \"1272\", \"supervisor\": \"Caldwell, Jennifer\", \"supervisorEId\": \"9\"}                   |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"5\", \"displayName\": \"Ashley Adams\", \"firstName\": \"Ashley\", \"lastName\": \"Adams\", \"preferredName\": null, \"dateOfBirth\": \"1984-02-02\", \"maritalStatus\": \"Married\", \"ssn\": \"545-66-7890\", \"gender\": \"Female\", \"pronouns\": null, \"country\": \"United States\", \"city\": \"Lindon\", \"zipcode\": \"84042\", \"address1\": \"335 S 560 W\", \"address2\": null, \"customShirtsize\": \"2. Medium\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Peanut allergy\", \"jobTitle\": \"HR Administrator\", \"hireDate\": \"2024-08-27\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2024-08-27\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"London, UK\", \"workPhone\": \"+44 207 555 4730\", \"mobilePhone\": \"+44 207 555 6671\", \"workEmail\": \"aadams@efficientoffice.com\", \"department\": \"Human Resources\", \"division\": \"Europe\", \"workPhoneExtension\": \"130\", \"supervisor\": \"Caldwell, Jennifer\", \"supervisorEId\": \"9\"}                             |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"6\", \"displayName\": \"Christina Agluinda\", \"firstName\": \"Christina\", \"lastName\": \"Agluinda\", \"preferredName\": null, \"dateOfBirth\": \"1997-04-01\", \"maritalStatus\": \"Single\", \"ssn\": \"321-44-5678\", \"gender\": \"Female\", \"pronouns\": null, \"country\": \"Australia\", \"city\": \"Sydney\", \"zipcode\": \"2000\", \"address1\": \"100 Cumberland Street\", \"address2\": null, \"customShirtsize\": \"2. Medium\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Peanut allergy\", \"jobTitle\": \"HR Administrator\", \"hireDate\": \"2024-04-29\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2024-04-29\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Sydney, Australia\", \"workPhone\": \"+61 2 5555 3103\", \"mobilePhone\": \"+61 2 5555 1984\", \"workEmail\": \"cagluinda@efficientoffice.com\", \"department\": \"Human Resources\", \"division\": \"Asia-Pacific\", \"workPhoneExtension\": null, \"supervisor\": \"Caldwell, Jennifer\", \"supervisorEId\": \"9\"}|2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"7\", \"displayName\": \"Shannon Anderson\", \"firstName\": \"Shannon\", \"lastName\": \"Anderson\", \"preferredName\": null, \"dateOfBirth\": \"2000-12-11\", \"maritalStatus\": \"Married\", \"ssn\": null, \"gender\": \"Female\", \"pronouns\": null, \"country\": \"Canada\", \"city\": \"Vancouver\", \"zipcode\": \"V5Z 4L5\", \"address1\": \"900 West Georgia Street\", \"address2\": null, \"customShirtsize\": \"1. Small\", \"allergies\": null, \"dietaryRestrictions\": null, \"jobTitle\": \"HR Administrator\", \"hireDate\": \"2024-06-29\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2024-06-29\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Vancouver, Canada\", \"workPhone\": \"604-555-3131\", \"mobilePhone\": \"604-555-8808\", \"workEmail\": \"sanderson@efficientoffice.com\", \"department\": \"Human Resources\", \"division\": \"North America\", \"workPhoneExtension\": null, \"supervisor\": \"Caldwell, Jennifer\", \"supervisorEId\": \"9\"}                              |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"8\", \"displayName\": \"emiliano frigo\", \"firstName\": \"emiliano\", \"lastName\": \"frigo\", \"preferredName\": null, \"dateOfBirth\": \"1968-07-28\", \"maritalStatus\": null, \"ssn\": \"555-60-8731\", \"gender\": null, \"pronouns\": null, \"country\": \"United States\", \"city\": \"Lindon\", \"zipcode\": \"84042\", \"address1\": \"335 S 560 W\", \"address2\": null, \"customShirtsize\": \"2. Medium\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Gluten\", \"jobTitle\": \"Sr. HR Administrator\", \"hireDate\": \"2021-11-27\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2024-11-21\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Lindon, Utah\", \"workPhone\": \"801-724-6600\", \"mobilePhone\": \"801-724-6600\", \"workEmail\": \"emiliano.frigo@muttdata.ai\", \"department\": \"Operations\", \"division\": \"North America\", \"workPhoneExtension\": \"123\", \"supervisor\": null, \"supervisorEId\": null}                                                         |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"9\", \"displayName\": \"Jennifer Caldwell\", \"firstName\": \"Jennifer\", \"lastName\": \"Caldwell\", \"preferredName\": null, \"dateOfBirth\": \"1975-10-02\", \"maritalStatus\": null, \"ssn\": \"555-64-9232\", \"gender\": null, \"pronouns\": null, \"country\": \"United States\", \"city\": \"Lindon\", \"zipcode\": \"84062\", \"address1\": \"335 S 560 W\", \"address2\": null, \"customShirtsize\": \"2. Medium\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Peanut allergy\", \"jobTitle\": \"VP of People\", \"hireDate\": \"2021-11-27\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2021-12-01\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Lindon, Utah\", \"workPhone\": \"801-724-6600\", \"mobilePhone\": \"801-724-6600\", \"workEmail\": \"jcaldwell@efficientoffice.com\", \"department\": \"Human Resources\", \"division\": \"North America\", \"workPhoneExtension\": \"1274\", \"supervisor\": \"frigo, emiliano\", \"supervisorEId\": \"8\"}                              |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"10\", \"displayName\": \"Ryota Saito\", \"firstName\": \"Ryota\", \"lastName\": \"Saito\", \"preferredName\": null, \"dateOfBirth\": \"1969-08-02\", \"maritalStatus\": \"Single\", \"ssn\": \"555-85-6555\", \"gender\": \"Male\", \"pronouns\": null, \"country\": \"United States\", \"city\": \"Provo\", \"zipcode\": \"84604\", \"address1\": \"800 S Center St\", \"address2\": null, \"customShirtsize\": \"2. Medium\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Peanut allergy\", \"jobTitle\": \"Chief Operating Officer\", \"hireDate\": \"2021-11-27\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2022-01-04\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Lindon, Utah\", \"workPhone\": \"801-724-6600\", \"mobilePhone\": \"801-724-6600\", \"workEmail\": \"rsaito@efficientoffice.com\", \"department\": \"Operations\", \"division\": \"North America\", \"workPhoneExtension\": \"1275\", \"supervisor\": \"frigo, emiliano\", \"supervisorEId\": \"8\"}                             |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"11\", \"displayName\": \"Daniel Vance\", \"firstName\": \"Daniel\", \"lastName\": \"Vance\", \"preferredName\": null, \"dateOfBirth\": \"1979-03-28\", \"maritalStatus\": \"Married\", \"ssn\": \"555-85-3811\", \"gender\": \"Male\", \"pronouns\": null, \"country\": \"United States\", \"city\": \"Eagle Mountain\", \"zipcode\": \"84005\", \"address1\": \"9865 Broken Arrow Ave\", \"address2\": null, \"customShirtsize\": \"3. Large\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Peanut allergy\", \"jobTitle\": \"VP of Sales\", \"hireDate\": \"2021-11-27\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2021-11-27\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Lindon, Utah\", \"workPhone\": \"801-724-6600\", \"mobilePhone\": \"801-724-6600\", \"workEmail\": \"dvance@efficientoffice.com\", \"department\": \"Sales\", \"division\": \"North America\", \"workPhoneExtension\": \"1276\", \"supervisor\": \"frigo, emiliano\", \"supervisorEId\": \"8\"}                             |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"12\", \"displayName\": \"Eric Asture\", \"firstName\": \"Eric\", \"lastName\": \"Asture\", \"preferredName\": null, \"dateOfBirth\": \"1990-10-07\", \"maritalStatus\": \"Single\", \"ssn\": \"555-60-5596\", \"gender\": \"Male\", \"pronouns\": null, \"country\": \"United States\", \"city\": \"Lindon\", \"zipcode\": \"84042\", \"address1\": \"9632 E 400 N\", \"address2\": null, \"customShirtsize\": \"4. XLarge\", \"allergies\": \"Peanuts\", \"dietaryRestrictions\": \"Peanut Allergy\", \"jobTitle\": \"VP of IT\", \"hireDate\": \"2021-11-27\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2021-11-27\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Lindon, Utah\", \"workPhone\": \"801-724-6600\", \"mobilePhone\": \"801-724-6600\", \"workEmail\": \"easture@efficientoffice.com\", \"department\": \"IT\", \"division\": \"North America\", \"workPhoneExtension\": \"1277\", \"supervisor\": \"frigo, emiliano\", \"supervisorEId\": \"8\"}                                                     |2025-01-31 10:36:54.557|\n",
      "|{\"id\": \"13\", \"displayName\": \"Cheryl Barnet\", \"firstName\": \"Cheryl\", \"lastName\": \"Barnet\", \"preferredName\": null, \"dateOfBirth\": \"1988-01-19\", \"maritalStatus\": \"Married\", \"ssn\": \"555-49-7785\", \"gender\": \"Female\", \"pronouns\": null, \"country\": \"United States\", \"city\": \"Eagle Mountain\", \"zipcode\": \"84005\", \"address1\": \"4908 E Woodhaven Blvd\", \"address2\": null, \"customShirtsize\": null, \"allergies\": null, \"dietaryRestrictions\": null, \"jobTitle\": \"VP of Customer Success\", \"hireDate\": \"2021-11-27\", \"originalHireDate\": \"0000-00-00\", \"employeeStatusDate\": \"2021-11-27\", \"status\": \"Active\", \"employmentHistoryStatus\": \"Full-Time\", \"terminationDate\": \"0000-00-00\", \"location\": \"Lindon, Utah\", \"workPhone\": \"801-724-6600\", \"mobilePhone\": \"801-555-6477\", \"workEmail\": \"cbarnet@efficientoffice.com\", \"department\": \"Customer Success\", \"division\": \"North America\", \"workPhoneExtension\": \"1278\", \"supervisor\": \"frigo, emiliano\", \"supervisorEId\": \"8\"}                         |2025-01-31 10:36:54.557|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check decryption\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"app_name\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "delta_table_path = \"data/delta_tables/employees\"\n",
    "\n",
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "df = decrypt_columns(df, columns=[\"value\"])\n",
    "df.show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
