{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql.types import StringType\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import DataFrame, SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "encryption_key = os.getenv(\"ENCRYPTION_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BambooHR API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BambooHRClient:\n",
    "    \"\"\"A client for the BambooHR API.\n",
    "    This client handles authentication, session management, and API requests\n",
    "    to the BambooHR API or a placeholder API for demonstration purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    DOMAIN = \"muttclip\"\n",
    "    BASE_URL = f\"https://api.bamboohr.com/api/gateway.php/{DOMAIN}/v1\"\n",
    "    ENDPOINTS = {\n",
    "        \"company_information\": \"/company_information\",\n",
    "        \"employees\": \"/employees/directory\",\n",
    "        \"employees_changed\": \"/employees/changed\",\n",
    "        \"employees_supervisors\": \"/reports/custom\",\n",
    "        \"account_info_fields\": \"/meta/fields\",\n",
    "        \"account_info_tab_fields\": \"/meta/tables\",\n",
    "        \"account_list_fields\": \"/meta/lists\",\n",
    "        \"account_list_users\": \"/meta/users\",\n",
    "        \"time_off_types\": \"/meta/time_off/types\",\n",
    "        \"time_off_policies\": \"/meta/time_off/policies\",\n",
    "        \"time_off_requests\": \"/time_off/requests\",\n",
    "        \"time_off_whos_out\": \"/time_off/whos_out\",\n",
    "        \"custom_report_test\": \"/reports/101\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"Initialize the BambooHRClient with an API key.\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = self.BASE_URL\n",
    "        self.session = self._create_session()\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": self._encode_auth_header(api_key),\n",
    "        }\n",
    "\n",
    "    def _encode_auth_header(self, api_key: str) -> str:\n",
    "        \"\"\"Encode the API key in Base64 for the Authorization header.\"\"\"\n",
    "        auth_string = f\"{api_key}:x\"\n",
    "        encoded_bytes = base64.b64encode(auth_string.encode(\"utf-8\"))\n",
    "        return f\"Basic {encoded_bytes.decode('utf-8')}\"\n",
    "\n",
    "    def _build_query_string(self, params: dict) -> str:\n",
    "        \"\"\"Helper method to construct a query string from a dictionary.\"\"\"\n",
    "        return \"&\".join(f\"{k}={v}\" for k, v in params.items())\n",
    "\n",
    "    def _create_session(self) -> requests.Session:\n",
    "        \"\"\"Create a session with a retry strategy for handling transient errors.\"\"\"\n",
    "        retry_strategy = Retry(\n",
    "            total=5,\n",
    "            backoff_factor=2,\n",
    "            status_forcelist=[429, 503],\n",
    "            allowed_methods=[\"GET\", \"POST\"],\n",
    "        )\n",
    "\n",
    "        # Create an adapter with the retry strategy\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "        # Create a session and mount the adapter\n",
    "        session = requests.Session()\n",
    "        session.mount(\"https://\", adapter)\n",
    "\n",
    "        return session\n",
    "\n",
    "    def get(self, endpoint_key: str, params: dict = None) -> dict:\n",
    "        \"\"\"\n",
    "        Fetch data from a specified endpoint using the endpoint key.\n",
    "\n",
    "        Args:\n",
    "            endpoint_key (str): The key for the desired endpoint (e.g., \"posts\").\n",
    "            params (dict, optional): Query parameters to include in the request.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an invalid endpoint key is provided.\n",
    "            requests.exceptions.RequestException: If the request fails.\n",
    "        \"\"\"\n",
    "        endpoint = self.ENDPOINTS.get(endpoint_key)\n",
    "        if not endpoint:\n",
    "            raise ValueError(f\"Invalid endpoint key: {endpoint_key}\")\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        response = self.session.get(url, headers=self.headers, params=params)\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed with status {response.status_code}: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    def get_employees_changed(self, days_offset: int = 1, change_type: str = None) -> dict:\n",
    "        \"\"\"\n",
    "        Fetch the list of employees changed since a given number of days ago.\n",
    "\n",
    "        Args:\n",
    "            days_offset (int, optional): The number of days prior to the current date \n",
    "                to use as the starting point for fetching changes. Defaults to 1.\n",
    "            change_type (str, optional): Type of change to filter for (\"inserted\", \"updated\", \"deleted\").\n",
    "                If not provided, all change types will be included.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API, containing the list of employees \n",
    "                who have changed since the specified timestamp.\n",
    "\n",
    "        \"\"\"\n",
    "        since = datetime.now(timezone.utc) - timedelta(days=days_offset)\n",
    "        since = since.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        \n",
    "        params = {\"since\": since}\n",
    "        if change_type:\n",
    "            params[\"type\"] = change_type\n",
    "\n",
    "        return self.get(\"employees_changed\", params=params)\n",
    "\n",
    "    def get_time_off_request(self, days_offset: int = 1) -> dict:\n",
    "        \"\"\"\n",
    "        Fetch time-off requests within a specified date range.\n",
    "\n",
    "        Args:\n",
    "            days_offset (int, optional): The number of days prior to the current date \n",
    "                to use as the start of the date range. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API, containing the list of time-off \n",
    "                requests within the specified date range.\n",
    "        \"\"\"\n",
    "        start_dt = datetime.now(timezone.utc) - timedelta(days=days_offset)\n",
    "        end_dt = datetime.now(timezone.utc)\n",
    "        start_dt = start_dt.strftime(\"%Y-%m-%d\")\n",
    "        end_dt = end_dt.strftime(\"%Y-%m-%d\")\n",
    "        params = {\n",
    "            \"start\": start_dt,\n",
    "            \"end\": end_dt,\n",
    "        }\n",
    "\n",
    "        return self.get(\"time_off_requests\", params=params)\n",
    "\n",
    "    def post(self, endpoint_key: str, data: dict = None, query_params: dict = None) -> dict:\n",
    "        \"\"\"\n",
    "        Send data to a specified endpoint using the POST method.\n",
    "\n",
    "        Args:\n",
    "            endpoint_key (str): The key for the desired endpoint.\n",
    "            data (dict, optional): The JSON payload to send in the POST request.\n",
    "            query_params (dict, optional): Query parameters to include in the URL.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an invalid endpoint key is provided.\n",
    "            requests.exceptions.RequestException: If the request fails.\n",
    "        \"\"\"\n",
    "        endpoint = self.ENDPOINTS.get(endpoint_key)\n",
    "        if not endpoint:\n",
    "            raise ValueError(f\"Invalid endpoint key: {endpoint_key}\")\n",
    "        \n",
    "        if query_params:\n",
    "            query_string = self._build_query_string(query_params)\n",
    "            url = f\"{self.base_url}{endpoint}?{query_string}\"\n",
    "        else:\n",
    "            url = f\"{self.base_url}{endpoint}\"\n",
    "        \n",
    "        response = self.session.post(url, headers=self.headers, json=data)\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed with status {response.status_code}: {e}\")\n",
    "            raise\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "    def create_employees_supervisors(self) -> dict:\n",
    "        \"\"\"\n",
    "        Generate a custom report of employees and their supervisors.\n",
    "\n",
    "        This method creates a custom report that includes fields for employees' first\n",
    "        names, last names, supervisors, and supervisor IDs.\n",
    "\n",
    "        Returns:\n",
    "            dict: The JSON response from the API with the generated report.\n",
    "        \"\"\"\n",
    "        payload= {\n",
    "            \"title\": \"employees-supervisors\",\n",
    "            \"fields\": [\"firstName\", \"lastName\", \"supervisor\", \"supervisorEid\"]\n",
    "        }\n",
    "        q_params={\"format\": \"json\", \"onlyCurrent\": \"true\"}\n",
    "    \n",
    "        return self.post(\n",
    "            \"employees_supervisors\", \n",
    "            data=payload,\n",
    "            query_params=q_params\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = BambooHRClient(api_key=api_key)\n",
    "\n",
    "# Create a data directory to store the JSON outputs\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "def save_json_data(data: dict, filename: str) -> None:\n",
    "    \"\"\"Save JSON data to a file.\"\"\"\n",
    "    with open(f\"data/{filename}\", \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"{filename} file saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_information.json file saved successfully\n",
      "employees.json file saved successfully\n",
      "employees_changed.json file saved successfully\n",
      "employees_supervisors.json file saved successfully\n",
      "account_info_fields.json file saved successfully\n",
      "account_info_tab_fields.json file saved successfully\n",
      "account_list_fields.json file saved successfully\n",
      "account_list_users.json file saved successfully\n",
      "time_off_types.json file saved successfully\n",
      "time_off_policies.json file saved successfully\n",
      "time_off_requests.json file saved successfully\n",
      "time_off_whos_out.json file saved successfully\n",
      "custom_report_test.json file saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Map report methods or endpoint keys to filenames\n",
    "report_mappings = {\n",
    "    \"company_information\": \"company_information.json\",\n",
    "    \"employees\": \"employees.json\",\n",
    "    \"employees_changed\": lambda: client.get_employees_changed(days_offset=7),\n",
    "    \"employees_supervisors\": lambda: client.create_employees_supervisors(),\n",
    "    \"account_info_fields\": \"account_info_fields.json\",\n",
    "    \"account_info_tab_fields\": \"account_info_tab_fields.json\",\n",
    "    \"account_list_fields\": \"account_list_fields.json\",\n",
    "    \"account_list_users\": \"account_list_users.json\",\n",
    "    \"time_off_types\": \"time_off_types.json\",\n",
    "    \"time_off_policies\": \"time_off_policies.json\",\n",
    "    \"time_off_requests\": lambda: client.get_time_off_request(days_offset=7),\n",
    "    \"time_off_whos_out\": \"time_off_whos_out.json\",\n",
    "    \"custom_report_test\": \"custom_report_test.json\",\n",
    "}\n",
    "\n",
    "# Fetch and save reports dynamically\n",
    "for report_key, filename_or_callable in report_mappings.items():\n",
    "    if callable(filename_or_callable):\n",
    "        data = filename_or_callable()\n",
    "        filename = f\"{report_key}.json\"\n",
    "    else:\n",
    "        data = client.get(report_key)\n",
    "        filename = filename_or_callable\n",
    "    save_json_data(data, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and Save data in delta format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DeltaFileManager:\n",
    "#     \"\"\"Handles the creation, transformation, and storage of data in Delta format.\"\"\"\n",
    "\n",
    "#     def __init__(self, app_name: str = \"MyApp\", encryption_key: str = None):\n",
    "#         \"\"\"\n",
    "#         Initializes the Spark session with Delta Lake configurations and optionally sets the encryption key.\n",
    "\n",
    "#         Args:\n",
    "#             app_name (str): Name of the Spark application.\n",
    "#             encryption_key (str): Encryption key for AES encryption (default: None).\n",
    "#         \"\"\"\n",
    "#         builder = (\n",
    "#             SparkSession.builder.appName(app_name)\n",
    "#             .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "#             .config(\n",
    "#                 \"spark.sql.catalog.spark_catalog\",\n",
    "#                 \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "#             )\n",
    "#         )\n",
    "#         self.spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "#         self.encryption_key = encryption_key\n",
    "\n",
    "#     def convert_to_json_string(self, data: List[dict]) -> list:\n",
    "#         \"\"\"\n",
    "#         Converts a list of dictionaries into a list of JSON strings.\n",
    "\n",
    "#         This method serializes each dictionary in the input list into a JSON-formatted\n",
    "#         string. The `default=str` parameter ensures that non-serializable types\n",
    "#         (e.g., datetime objects) are converted to strings during serialization.\n",
    "#         \"\"\"\n",
    "#         return [json.dumps(record, default=str) for record in data]\n",
    "\n",
    "#     def create_schemaless_df(self, json_strings: list) -> DataFrame:\n",
    "#         \"\"\"Converts a list of JSON strings into a schemaless DataFrame.\"\"\"\n",
    "#         return self.spark.createDataFrame(json_strings, StringType())\n",
    "\n",
    "#     def add_processed_dt(self, df: DataFrame) -> DataFrame:\n",
    "#         \"\"\"Adds a processed timestamp column to a DataFrame.\"\"\"\n",
    "#         return df.withColumn(\"processed_at\", F.current_timestamp())\n",
    "\n",
    "#     def encrypt_columns(\n",
    "#         self,\n",
    "#         df: DataFrame,\n",
    "#         columns: list,\n",
    "#         encryption_mode: str = \"ECB\",\n",
    "#     ) -> DataFrame:\n",
    "#         \"\"\"\n",
    "#         Encrypts the specified columns in the DataFrame using AES encryption and Base64 encoding.\n",
    "\n",
    "#         Args:\n",
    "#             df (DataFrame): The input DataFrame.\n",
    "#             columns (list): List of column names to encrypt.\n",
    "#             encryption_mode (str): The encryption mode for AES (default: \"ECB\").\n",
    "\n",
    "#         Returns:\n",
    "#             DataFrame: The DataFrame with encrypted columns.\n",
    "#         \"\"\"\n",
    "#         if not self.encryption_key:\n",
    "#             raise ValueError(\"Encryption key is not set. Please provide an encryption key.\")\n",
    "\n",
    "#         for col_name in columns:\n",
    "#             encrypted_col = F.expr(f\"aes_encrypt({col_name}, '{self.encryption_key}', '{encryption_mode}')\")\n",
    "#             base64_encoded_col = F.base64(encrypted_col)\n",
    "#             df = df.withColumn(col_name, base64_encoded_col)\n",
    "#         return df\n",
    "\n",
    "#     def save_to_delta(\n",
    "#         self, df: DataFrame, path: str, repartition: int = 1, mode: str = \"append\"\n",
    "#     ):\n",
    "#         \"\"\"Saves a DataFrame to a Delta table.\"\"\"\n",
    "#         df.repartition(repartition).write.format(\"delta\").mode(mode).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the manager\n",
    "# manager = DeltaFileManager(encryption_key=encryption_key)\n",
    "\n",
    "# # Prepare input files into json_strings\n",
    "# posts_string = manager.convert_to_json_string(posts)\n",
    "# albums_string = manager.convert_to_json_string(albums)\n",
    "# users_string = manager.convert_to_json_string(users)\n",
    "\n",
    "# # Create schemaless DataFrames\n",
    "# posts_df = manager.create_schemaless_df(posts_string)\n",
    "# albums_df = manager.create_schemaless_df(albums_string)\n",
    "# users_df = manager.create_schemaless_df(users_string)\n",
    "\n",
    "# # Add a timestamp column\n",
    "# posts_df = manager.add_processed_dt(posts_df)\n",
    "# albums_df = manager.add_processed_dt(albums_df)\n",
    "# users_df = manager.add_processed_dt(users_df)\n",
    "\n",
    "# # Encrypt data\n",
    "# posts_df = manager.encrypt_columns(posts_df, columns=[\"value\"])\n",
    "# albums_df = manager.encrypt_columns(albums_df, columns=[\"value\"])\n",
    "# users_df = manager.encrypt_columns(users_df, columns=[\"value\"])\n",
    "\n",
    "# # Save to Delta tables\n",
    "# manager.save_to_delta(posts_df, \"data/delta_tables/posts\", mode=\"overwrite\")\n",
    "# manager.save_to_delta(albums_df, \"data/delta_tables/albums\", mode=\"overwrite\")\n",
    "# manager.save_to_delta(users_df, \"data/delta_tables/users\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Schemas\n",
    "# posts_df.printSchema()\n",
    "# albums_df.printSchema()\n",
    "# users_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display results\n",
    "# posts_df.show(1, truncate=False)\n",
    "# albums_df.show(1, truncate=False)\n",
    "# users_df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypt value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decrypt_columns(\n",
    "#         df: DataFrame, \n",
    "#         columns: list, \n",
    "#         encryption_key: str = encryption_key, \n",
    "#         encryption_mode: str = \"ECB\") -> DataFrame:\n",
    "#     \"\"\"\n",
    "#     Decrypts the specified columns in the DataFrame using AES decryption and Base64 decoding.\n",
    "\n",
    "#     Args:\n",
    "#         df (DataFrame): The input DataFrame.\n",
    "#         columns (list): List of column names to decrypt.\n",
    "#         encryption_key (str): The decryption key for AES decryption.\n",
    "#         encryption_mode (str): The decryption mode for AES (default: \"ECB\").\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: The DataFrame with decrypted columns.\n",
    "#     \"\"\"\n",
    "#     for col_name in columns:\n",
    "#         decrypted_col = F.expr(\n",
    "#             f\"aes_decrypt(unbase64({col_name}), '{encryption_key}', '{encryption_mode}')\"\n",
    "#         ).cast(\"string\")\n",
    "#         df = df.withColumn(col_name, decrypted_col)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encrypt data\n",
    "# posts_df = decrypt_columns(posts_df, columns=[\"value\"])\n",
    "# albums_df = decrypt_columns(albums_df, columns=[\"value\"])\n",
    "# users_df = decrypt_columns(users_df, columns=[\"value\"])\n",
    "\n",
    "# # Display results\n",
    "# posts_df.show(1, truncate=False)\n",
    "# albums_df.show(1, truncate=False)\n",
    "# users_df.show(1, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
