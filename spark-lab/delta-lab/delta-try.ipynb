{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pyspark\n",
    "\n",
    "from delta import *\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/emif/Documents/spark-lab/.venv/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/emif/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/emif/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-632bce36-bffd-4ff1-b226-8b695cf85990;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;1.2.1 in central\n",
      "\tfound io.delta#delta-storage;1.2.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      ":: resolution report :: resolve 303ms :: artifacts dl 20ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;1.2.1 from central in [default]\n",
      "\tio.delta#delta-storage;1.2.1 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-632bce36-bffd-4ff1-b226-8b695cf85990\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/9ms)\n",
      "22/06/16 15:36:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: https://docs.delta.io/latest/quick-start.html#pyspark-shell\n",
    "\n",
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder\n",
    "    .appName(\"SparkSQLExampleApp\")\n",
    "    .master(\"local[4]\")\n",
    "    .config(\"spark.sql.shuffle.partition\", 4)\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \n",
    "            \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "    )\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    configure_spark_with_delta_pip(builder).getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\"CallNumber INT,\n",
    "            UnitID STRING,                     \n",
    "            IncidentNumber INT,           \n",
    "            CallType STRING,                   \n",
    "            CallDate STRING,                   \n",
    "            WatchDate STRING,                  \n",
    "            CallFinalDisposition STRING,       \n",
    "            AvailableDtTm STRING,              \n",
    "            Address STRING,                    \n",
    "            City STRING,                       \n",
    "            Zipcode  INT,                   \n",
    "            Battalion STRING,                  \n",
    "            StationArea INT,                \n",
    "            Box INT,                        \n",
    "            OriginalPriority INT,           \n",
    "            Priority INT,                   \n",
    "            FinalPriority INT,              \n",
    "            ALSUnit BOOLEAN,                    \n",
    "            CallTypeGroup STRING,              \n",
    "            NumAlarms INT,                \n",
    "            UnitType STRING,                   \n",
    "            UnitSequenceInCallDispatch INT, \n",
    "            FirePreventionDistrict INT,     \n",
    "            SupervisorDistrict INT,         \n",
    "            Neighborhood STRING,               \n",
    "            Location STRING,                   \n",
    "            RowID STRING,                      \n",
    "            Delay FLOAT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to file\n",
    "csv_file = \"/Users/emif/Documents/spark-lab/datasets/sf-fire-calls.csv\"\n",
    "\n",
    "# Read and create a temporary view\n",
    "df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .schema(schema)\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(csv_file)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleansed = (\n",
    "    df\n",
    "    .dropDuplicates(subset=[\"CallNumber\"])\n",
    "    .drop(\"Location\", \"RowID\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = (\n",
    "    df_cleansed\n",
    "    .withColumn(\"CallDate\", F.to_date(F.col(\"CallDate\"), \"dd/MM/yyyy\"))\n",
    "    .withColumn(\"WatchDate\", F.to_date(F.col(\"WatchDate\"), \"dd/MM/yyyy\"))\n",
    "    .withColumn(\"AvailableDtTm\", F.to_timestamp(F.col(\"AvailableDtTm\"), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "    .withColumn(\"CallYear\", F.year(\"CallDate\").cast(T.IntegerType()))\n",
    "    .na.drop(subset=[\"CallYear\"])\n",
    "    .withColumn(\"creation_date\", F.current_timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: date (nullable = true)\n",
      " |-- WatchDate: date (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: timestamp (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: integer (nullable = true)\n",
      " |-- Priority: integer (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      " |-- CallYear: integer (nullable = true)\n",
      " |-- creation_date: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{os.getcwd()}/storage/sf_fire_calls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old directory data\n",
    "try:\n",
    "    shutil.rmtree(path)\n",
    "except FileNotFoundError:\n",
    "    print(\"there is directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/16 15:36:54 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write base delta table\n",
    "(\n",
    "    df_final\n",
    "    .repartition(1)\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .partitionBy(\"CallYear\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_data = (\n",
    "    df_final\n",
    "    .filter(F.col(\"CallYear\") == 2018)\n",
    "    .withColumn(\"CallNumber\", F.col(\"CallNumber\") * F.lit(2))\n",
    "    .withColumn(\"CallYear\", F.col(\"CallYear\") + F.lit(1))\n",
    "    .withColumn(\"creation_date\", F.current_timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_deltaTable = DeltaTable.forPath(spark, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# merging new data to delta table\n",
    "(\n",
    "    tgt_deltaTable.alias(\"tgt\")\n",
    "    .merge(\n",
    "        df_new_data.alias(\"src\"), \"src.CallNumber = tgt.CallNumber\")\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated_data_2010 = (\n",
    "    df_final\n",
    "    .filter(F.col(\"CallYear\") == 2010)\n",
    "    .withColumn(\"Delay\", F.col(\"Delay\") * 2)\n",
    "    .withColumn(\"creation_date\", F.current_timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_deltaTable2 = DeltaTable.forPath(spark, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# merging updated 2010 data to delta table\n",
    "(\n",
    "    tgt_deltaTable2.alias(\"tgt\")\n",
    "    .merge(\n",
    "        df_updated_data_2010.alias(\"src\"), \n",
    "        \"src.CallNumber = tgt.CallNumber\")\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " version             | 2                                                                                                                                                                                                                                                                                        \n",
      " timestamp           | 2022-06-16 15:37:45.246                                                                                                                                                                                                                                                                  \n",
      " userId              | null                                                                                                                                                                                                                                                                                     \n",
      " userName            | null                                                                                                                                                                                                                                                                                     \n",
      " operation           | MERGE                                                                                                                                                                                                                                                                                    \n",
      " operationParameters | {predicate -> (src.CallNumber = tgt.CallNumber), matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}]}                                                                                                                                      \n",
      " job                 | null                                                                                                                                                                                                                                                                                     \n",
      " notebook            | null                                                                                                                                                                                                                                                                                     \n",
      " clusterId           | null                                                                                                                                                                                                                                                                                     \n",
      " readVersion         | 1                                                                                                                                                                                                                                                                                        \n",
      " isolationLevel      | Serializable                                                                                                                                                                                                                                                                             \n",
      " isBlindAppend       | false                                                                                                                                                                                                                                                                                    \n",
      " operationMetrics    | {numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, executionTimeMs -> 6702, numTargetRowsInserted -> 0, scanTimeMs -> 2617, numTargetRowsUpdated -> 3610, numOutputRows -> 3610, numSourceRows -> 3610, numTargetFilesRemoved -> 1, rewriteTimeMs -> 4063}  \n",
      " userMetadata        | null                                                                                                                                                                                                                                                                                     \n",
      " engineInfo          | Apache-Spark/3.2.1 Delta-Lake/1.2.1                                                                                                                                                                                                                                                      \n",
      "-RECORD 1-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " version             | 1                                                                                                                                                                                                                                                                                        \n",
      " timestamp           | 2022-06-16 15:37:35.375                                                                                                                                                                                                                                                                  \n",
      " userId              | null                                                                                                                                                                                                                                                                                     \n",
      " userName            | null                                                                                                                                                                                                                                                                                     \n",
      " operation           | MERGE                                                                                                                                                                                                                                                                                    \n",
      " operationParameters | {predicate -> (src.CallNumber = tgt.CallNumber), matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}]}                                                                                                                                      \n",
      " job                 | null                                                                                                                                                                                                                                                                                     \n",
      " notebook            | null                                                                                                                                                                                                                                                                                     \n",
      " clusterId           | null                                                                                                                                                                                                                                                                                     \n",
      " readVersion         | 0                                                                                                                                                                                                                                                                                        \n",
      " isolationLevel      | Serializable                                                                                                                                                                                                                                                                             \n",
      " isBlindAppend       | false                                                                                                                                                                                                                                                                                    \n",
      " operationMetrics    | {numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, executionTimeMs -> 10187, numTargetRowsInserted -> 4037, scanTimeMs -> 5133, numTargetRowsUpdated -> 0, numOutputRows -> 4037, numSourceRows -> 4037, numTargetFilesRemoved -> 0, rewriteTimeMs -> 5037} \n",
      " userMetadata        | null                                                                                                                                                                                                                                                                                     \n",
      " engineInfo          | Apache-Spark/3.2.1 Delta-Lake/1.2.1                                                                                                                                                                                                                                                      \n",
      "-RECORD 2-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " version             | 0                                                                                                                                                                                                                                                                                        \n",
      " timestamp           | 2022-06-16 15:37:18.31                                                                                                                                                                                                                                                                   \n",
      " userId              | null                                                                                                                                                                                                                                                                                     \n",
      " userName            | null                                                                                                                                                                                                                                                                                     \n",
      " operation           | WRITE                                                                                                                                                                                                                                                                                    \n",
      " operationParameters | {mode -> Overwrite, partitionBy -> [\"CallYear\"]}                                                                                                                                                                                                                                         \n",
      " job                 | null                                                                                                                                                                                                                                                                                     \n",
      " notebook            | null                                                                                                                                                                                                                                                                                     \n",
      " clusterId           | null                                                                                                                                                                                                                                                                                     \n",
      " readVersion         | null                                                                                                                                                                                                                                                                                     \n",
      " isolationLevel      | Serializable                                                                                                                                                                                                                                                                             \n",
      " isBlindAppend       | false                                                                                                                                                                                                                                                                                    \n",
      " operationMetrics    | {numFiles -> 19, numOutputRows -> 67690, numOutputBytes -> 2846902}                                                                                                                                                                                                                      \n",
      " userMetadata        | null                                                                                                                                                                                                                                                                                     \n",
      " engineInfo          | Apache-Spark/3.2.1 Delta-Lake/1.2.1                                                                                                                                                                                                                                                      \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/18 02:55:50 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 952738 ms exceeds timeout 120000 ms\n",
      "22/06/18 02:55:50 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "# check versions\n",
    "spark.sql(f\"describe history '{path}'\").show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+-----------------------+\n",
      "|CallNumber|CallYear|delay    |creation_date          |\n",
      "+----------+--------+---------+-----------------------+\n",
      "|100010030 |2010    |42.983334|2022-06-16 15:36:56.917|\n",
      "|100010087 |2010    |21.433332|2022-06-16 15:36:56.917|\n",
      "|100010098 |2010    |7.616667 |2022-06-16 15:36:56.917|\n",
      "|100010109 |2010    |23.883333|2022-06-16 15:36:56.917|\n",
      "|100010120 |2010    |5.35     |2022-06-16 15:36:56.917|\n",
      "|100010145 |2010    |2.1166666|2022-06-16 15:36:56.917|\n",
      "|100010147 |2010    |19.5     |2022-06-16 15:36:56.917|\n",
      "|100010163 |2010    |2.8833334|2022-06-16 15:36:56.917|\n",
      "|100010171 |2010    |1.2166667|2022-06-16 15:36:56.917|\n",
      "|100010187 |2010    |3.05     |2022-06-16 15:36:56.917|\n",
      "|100010203 |2010    |4.6      |2022-06-16 15:36:56.917|\n",
      "|100010205 |2010    |2.65     |2022-06-16 15:36:56.917|\n",
      "|100010209 |2010    |1.7666667|2022-06-16 15:36:56.917|\n",
      "|100010229 |2010    |2.9      |2022-06-16 15:36:56.917|\n",
      "|100010245 |2010    |2.4666667|2022-06-16 15:36:56.917|\n",
      "|100010248 |2010    |5.133333 |2022-06-16 15:36:56.917|\n",
      "|100010271 |2010    |1.8      |2022-06-16 15:36:56.917|\n",
      "|100010284 |2010    |6.8      |2022-06-16 15:36:56.917|\n",
      "|100010289 |2010    |3.5166667|2022-06-16 15:36:56.917|\n",
      "|100010291 |2010    |1.15     |2022-06-16 15:36:56.917|\n",
      "+----------+--------+---------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using time travel to check previous versions\n",
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"delta\")\n",
    "    .option(\"versionAsOf\", 1)\n",
    "    .load(path)\n",
    "    ###\n",
    "    .filter(F.col(\"CallYear\") == 2010)\n",
    "    .select(\"CallNumber\", \"CallYear\", \"delay\", \"creation_date\")\n",
    "    .orderBy(F.col(\"CallNumber\").asc())\n",
    "    .show(truncate=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe32d98a1ee141d9be34c10c16fbd81de181f41d0001c931301c6474f8fba72"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
